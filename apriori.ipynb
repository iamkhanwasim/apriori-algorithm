{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1</td>\n",
       "      <td>butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>bread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transactions    Item\n",
       "0           T1   bread\n",
       "1           T1  butter\n",
       "2           T1    milk\n",
       "3           T2    milk\n",
       "4           T3   bread"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  df = pd.DataFrame({\n",
    "#         'Transactions': ['T1','T1','T1','T2','T3','T3','T3','T3','T4','T4','T4','T5','T5','T6','T6','T6','T6','T7','T7','T8','T8','T9','T9','T9','T9','T10','T10'], \n",
    "#         'Item': ['bread','butter','milk','milk','bread','milk','sugar','tea','bread','butter','milk','milk','cereals','milk','coffee','sugar','tea','milk','bread','cereals','butter','bread','cereals','sugar','tea','bread','coffee']})\n",
    "# df.head()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'TID': ['T1','T1','T1','T2','T2','T2','T2','T2','T3','T3','T3','T4','T4','T4','T4','T5','T5','T5','T5'], \n",
    "        'Item': ['bread','butter','milk','bread','butter','coffee','sugar','milk','butter','coffee','milk','butter','coffee','sugar','milk','bread','butter','coffee']})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_hot_encoding(df):\n",
    "    \"\"\"\n",
    "        This method generates one hot encoding for pandas dataframe\n",
    "        Output to this method is also pandas dataframe\n",
    "        This method utlizes in-built method from pandas to return one-hot encoding\n",
    "    \"\"\"\n",
    "    one_hot_encoded = pd.get_dummies(df['Item'])\n",
    "    \n",
    "    basket = pd.concat([df['Transactions'], one_hot_encoded],axis=1)\n",
    "    basket = basket.groupby('Transactions').sum().reset_index()\n",
    "    return basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bread</th>\n",
       "      <th>butter</th>\n",
       "      <th>cereals</th>\n",
       "      <th>coffee</th>\n",
       "      <th>milk</th>\n",
       "      <th>sugar</th>\n",
       "      <th>tea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bread  butter  cereals  coffee  milk  sugar  tea\n",
       "0      1       1        0       0     1      0    0\n",
       "1      1       0        0       1     0      0    0\n",
       "2      0       0        0       0     1      0    0\n",
       "3      1       0        0       0     1      1    1\n",
       "4      1       1        0       0     1      0    0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket = generate_one_hot_encoding(df)\n",
    "basket = basket.drop(columns='Transactions', axis=1,)\n",
    "basket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frequent_itemsets(df, min_support=0.5):\n",
    "    \"\"\"\n",
    "    Implements Apriori algorithm to generate frequent itemsets from binary transaction data.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): A dataframe with binary values (0/1) where rows represent transactions and\n",
    "                       columns represent items.\n",
    "    min_support (float): Minimum support threshold.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary where keys are frequent itemsets (frozenset) and values are their support.\n",
    "    \"\"\"\n",
    "    # Number of transactions\n",
    "    num_transactions = len(df)\n",
    "    \n",
    "    # Step 1: Find frequent 1-itemsets\n",
    "    item_support = {}\n",
    "    for column in df.columns:\n",
    "        \n",
    "        print(type(int(df[column].sum())))\n",
    "        print(type(num_transactions))\n",
    "        support = int(df[column].sum()) / num_transactions\n",
    "        if support >= min_support:\n",
    "            item_support[frozenset([column])] = support\n",
    "    \n",
    "    # Initialize the frequent itemsets with frequent 1-itemsets\n",
    "    frequent_itemsets = item_support.copy()\n",
    "    \n",
    "    # Step 2: Generate candidate itemsets of size k and filter by min_support\n",
    "    k = 2\n",
    "    current_itemsets = list(item_support.keys())\n",
    "    \n",
    "    while current_itemsets:\n",
    "        # Generate candidate itemsets of size k by combining k-1 itemsets\n",
    "        candidate_itemsets = []\n",
    "        for i in range(len(current_itemsets)):\n",
    "            for j in range(i + 1, len(current_itemsets)):\n",
    "                candidate = current_itemsets[i].union(current_itemsets[j])\n",
    "                if len(candidate) == k:\n",
    "                    candidate_itemsets.append(candidate)\n",
    "        \n",
    "        # Calculate support for candidate itemsets\n",
    "        candidate_support = {}\n",
    "        for candidate in candidate_itemsets:\n",
    "            # Check how many transactions contain this candidate\n",
    "            support = df[list(candidate)].all(axis=1).sum() / num_transactions\n",
    "            if support >= min_support:\n",
    "                candidate_support[frozenset(candidate)] = support\n",
    "        \n",
    "        # Add frequent k-itemsets to the result\n",
    "        frequent_itemsets.update(candidate_support)\n",
    "        \n",
    "        # Prepare for the next iteration (generate k+1 itemsets)\n",
    "        current_itemsets = list(candidate_support.keys())\n",
    "        k += 1\n",
    "    \n",
    "    return frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "def generate_rules(frequent_itemsets, min_confidence=0.5):\n",
    "    \"\"\"\n",
    "    Generate association rules from frequent itemsets along with confidence and lift metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    frequent_itemsets (dict): Dictionary where keys are itemsets and values are their support.\n",
    "    min_confidence (float): Minimum confidence threshold for filtering rules.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame of rules with antecedent, consequent, confidence, and lift.\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    itemsets = list(frequent_itemsets.keys())\n",
    "    \n",
    "    for itemset in itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            # For each frequent itemset, generate all possible non-empty proper subsets (A)\n",
    "            for i in range(1, len(itemset)):\n",
    "                for antecedent in combinations(itemset, i):\n",
    "                    antecedent = frozenset(antecedent)\n",
    "                    consequent = itemset - antecedent\n",
    "                    \n",
    "                    if consequent:\n",
    "                        # Calculate confidence: P(A → B) = support(A ∪ B) / support(A)\n",
    "                        confidence = frequent_itemsets[itemset] / frequent_itemsets[antecedent]\n",
    "                        \n",
    "                        # Only consider rules with confidence greater than or equal to min_confidence\n",
    "                        if confidence >= min_confidence:\n",
    "                            # Calculate lift: Lift(A → B) = confidence(A → B) / support(B)\n",
    "                            lift = confidence / frequent_itemsets[consequent]\n",
    "                            \n",
    "                            # Append the rule as a row to the list\n",
    "                            rules.append({\n",
    "                                'antecedent': set(antecedent),\n",
    "                                'consequent': set(consequent),\n",
    "                                'confidence': confidence,\n",
    "                                'lift': lift\n",
    "                            })\n",
    "    \n",
    "    # Convert the list of rules to a DataFrame\n",
    "    return pd.DataFrame(rules)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rules_2(frequent_itemsets, min_confidence=0.5, max_antecedent=3, max_consequent=3):\n",
    "    \"\"\"\n",
    "    Generate association rules from frequent itemsets along with confidence, lift, and support metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    frequent_itemsets (dict): Dictionary where keys are itemsets (frozenset) and values are their support.\n",
    "    min_confidence (float): Minimum confidence threshold for filtering rules.\n",
    "    max_antecedent (int): Maximum number of items allowed in the antecedent.\n",
    "    max_consequent (int): Maximum number of items allowed in the consequent.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame of rules with antecedent, consequent, confidence, lift, and support.\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    itemsets = list(frequent_itemsets.keys())\n",
    "    \n",
    "    for itemset in itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            # For each frequent itemset, generate all possible non-empty proper subsets (A)\n",
    "            for i in range(1, min(max_antecedent, len(itemset)) + 1):\n",
    "                for antecedent in combinations(itemset, i):\n",
    "                    antecedent = frozenset(antecedent)\n",
    "                    consequent = itemset - antecedent\n",
    "                    \n",
    "                    if consequent and len(consequent) <= max_consequent:\n",
    "                        # Calculate confidence: P(A → B) = support(A ∪ B) / support(A)\n",
    "                        confidence = frequent_itemsets[itemset] / frequent_itemsets[antecedent]\n",
    "                        \n",
    "                        # Only consider rules with confidence greater than or equal to min_confidence\n",
    "                        if confidence >= min_confidence:\n",
    "                            # Calculate lift: Lift(A → B) = confidence(A → B) / support(B)\n",
    "                            lift = confidence / frequent_itemsets[frozenset(consequent)]\n",
    "                            \n",
    "                            # Get support for the full itemset (antecedent ∪ consequent)\n",
    "                            support = frequent_itemsets[itemset]\n",
    "                            \n",
    "                            # Append the rule as a row to the list\n",
    "                            rules.append({\n",
    "                                'antecedent': antecedent,\n",
    "                                'consequent': frozenset(consequent),                                \n",
    "                                'support': support,\n",
    "                                'confidence': confidence,\n",
    "                                'lift': lift,\n",
    "                            })\n",
    "    \n",
    "    # Convert the list of rules to a DataFrame\n",
    "    return pd.DataFrame(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rules_3(frequent_itemsets, min_confidence=0.5, max_antecedent=2, max_consequent=2):\n",
    "    \"\"\"\n",
    "    Generate association rules from frequent itemsets along with confidence, lift, and support metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    frequent_itemsets (dict): Dictionary where keys are itemsets (frozenset) and values are their support.\n",
    "    min_confidence (float): Minimum confidence threshold for filtering rules.\n",
    "    max_antecedent (int): Maximum number of items allowed in the antecedent.\n",
    "    max_consequent (int): Maximum number of items allowed in the consequent.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame of rules with antecedent, consequent, confidence, lift, and support.\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    itemsets = list(frequent_itemsets.keys())\n",
    "    \n",
    "    for itemset in itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            # For each frequent itemset, generate all possible non-empty proper subsets (A)\n",
    "            for i in range(1, min(max_antecedent, len(itemset)) + 1):\n",
    "                for antecedent in combinations(itemset, i):\n",
    "                    antecedent = frozenset(antecedent)\n",
    "                    consequent = itemset - antecedent\n",
    "                    \n",
    "                    if consequent and len(consequent) <= max_consequent:\n",
    "                        # Calculate confidence: P(A → B) = support(A ∪ B) / support(A)\n",
    "                        confidence = frequent_itemsets[itemset] / frequent_itemsets[antecedent]\n",
    "                        \n",
    "                        # Only consider rules with confidence greater than or equal to min_confidence\n",
    "                        if confidence >= min_confidence:\n",
    "                            # Calculate lift: Lift(A → B) = confidence(A → B) / support(B)\n",
    "                            lift = confidence / frequent_itemsets[frozenset(consequent)]\n",
    "                            \n",
    "                            # Get support for the full itemset (antecedent ∪ consequent)\n",
    "                            support = frequent_itemsets[itemset]\n",
    "                            \n",
    "                            # Convert sets to strings for display without brackets\n",
    "                            rules.append({\n",
    "                                'antecedent': ', '.join(antecedent),\n",
    "                                'consequent': ', '.join(consequent),\n",
    "                                'confidence': confidence,\n",
    "                                'lift': lift,\n",
    "                                'support': support\n",
    "                            })\n",
    "    \n",
    "    # Convert the list of rules to a DataFrame\n",
    "    return pd.DataFrame(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedent</th>\n",
       "      <th>consequent</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>tea, milk</td>\n",
       "      <td>coffee, sugar</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>tea, coffee</td>\n",
       "      <td>sugar, milk</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>tea, sugar</td>\n",
       "      <td>coffee, milk</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>coffee, milk</td>\n",
       "      <td>tea, sugar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>sugar, milk</td>\n",
       "      <td>tea, coffee</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>coffee, sugar</td>\n",
       "      <td>tea, milk</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>tea, coffee, milk</td>\n",
       "      <td>sugar</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>sugar, tea, milk</td>\n",
       "      <td>coffee</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tea, coffee, sugar</td>\n",
       "      <td>milk</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>sugar, coffee, milk</td>\n",
       "      <td>tea</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              antecedent     consequent  confidence      lift  support\n",
       "132            tea, milk  coffee, sugar    0.500000  5.000000      0.1\n",
       "133          tea, coffee    sugar, milk    1.000000  5.000000      0.1\n",
       "134           tea, sugar   coffee, milk    0.333333  3.333333      0.1\n",
       "135         coffee, milk     tea, sugar    1.000000  3.333333      0.1\n",
       "136          sugar, milk    tea, coffee    0.500000  5.000000      0.1\n",
       "137        coffee, sugar      tea, milk    1.000000  5.000000      0.1\n",
       "138    tea, coffee, milk          sugar    1.000000  3.333333      0.1\n",
       "139     sugar, tea, milk         coffee    0.500000  2.500000      0.1\n",
       "140   tea, coffee, sugar           milk    1.000000  1.428571      0.1\n",
       "141  sugar, coffee, milk            tea    1.000000  3.333333      0.1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage with frequent itemsets from the previous step\n",
    "frequent_itemsets = generate_frequent_itemsets(basket, 0.1)\n",
    "# print(frequent_itemsets)\n",
    "# Minimum confidence threshold\n",
    "min_confidence = 0.1\n",
    "\n",
    "# Generate rules\n",
    "rules_df = generate_rules_3(frequent_itemsets, min_confidence,5,5)\n",
    "\n",
    "# Display the rules DataFrame\n",
    "rules_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_df.to_csv('apriori_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
